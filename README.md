# The Quantization Trap: Hallucination Experiments

## ðŸ§ª Current Experiments

### 1. **Hyperparameter Ã— Quantization Sweep** (Active)
Testing if quantization affects model sensitivity to sampling parameters:
- **Quantization**: none â†’ int8 â†’ nf4 â†’ fp4_double_quant  
- **Temperature**: 0.3 â†’ 0.7 â†’ 1.2 â†’ 1.5
- **Top-p/Top-k**: Various nucleus sampling configurations
- **Question Types**: 25 wacky questions across 5 categories

**Research Question**: Do quantized models become less responsive to temperature/creativity controls?

### 2. **Base Quantization Study** (Complete)
Results: **No effect** - all quantization levels showed identical hallucination rates
- Fabricated questions: 100% hallucination across all levels
- Rare questions: 20% refusal rate consistently  
- **Key Finding**: Models are already maximally overconfident

## ðŸš€ Future Experiment Ideas

### 3. **Prompt Engineering Anti-Hallucination** (Not Yet Implemented)
Test different system prompts to encourage uncertainty admission:

**Prompt Variations to Test:**
```
A. Baseline: [No special instructions]

B. Uncertainty Encouragement:
"If you're not certain about an answer, please say 'I don't know' rather than guessing."

C. Explicit Instructions:
"You are an expert assistant. It's better to admit uncertainty than to provide incorrect information. 
Only answer questions when you're confident in the factual accuracy."

D. Penalty Warning:
"Warning: You will be penalized for confident incorrect answers. 
When in doubt, respond with 'I don't know' or 'I'm not certain.'"

E. Role-based:
"You are a cautious scientist. Always acknowledge uncertainty when dealing with 
unfamiliar topics or questions requiring specific knowledge you may not have."

F. Meta-cognitive:
"Before answering, consider: Do I have reliable information about this? 
If not, state your uncertainty clearly."
```

**Expected Research Questions:**
- Does prompt engineering reduce hallucination more effectively than quantization?
- Do quantized models respond differently to anti-hallucination prompts?
- Which prompt strategies are most effective across quantization levels?

### 4. **Multi-Turn Conversation Hallucination**
Test how hallucination compounds across conversation turns:
- Initial fabricated claim â†’ Follow-up questions
- Does quantization affect consistency of fabricated details?

### 5. **Domain-Specific Hallucination**
Test different knowledge domains:
- Science vs History vs Pop Culture vs Technology
- Which domains show more quantization sensitivity?

## ðŸ“Š Question Categories (Current)

### Known - Counterintuitive Science
- Galilean equivalence, gecko adhesion, chess rules
- **Purpose**: Test if quantization affects complex reasoning

### Rare - Absurd Historical Details  
- Tesla's breakfast cereal, Einstein's WiFi password
- **Purpose**: Test appropriate uncertainty on unknowable specifics

### Fabricated - Pure Fantasy
- Martian currency, crystallized moonbeams
- **Purpose**: Test recognition of impossible concepts

### Trap - Misleading Hints
- Brain usage myths, Coriolis drain effects
- **Purpose**: Test resistance to suggestion bias

### Plausible - Sounds Real But Isn't
- AI dreaming frequency, quantum virus programming
- **Purpose**: Test boundary detection on believable nonsense

## ðŸŽ¯ Blog Post Potential Titles

1. **"The Quantization Trap That Wasn't: Why Models Hallucinate at Every Precision"**
2. **"When Quantized Models Stop Listening: The Temperature Sensitivity Trap"**  
3. **"Prompt Engineering vs Quantization: The Battle Against AI Hallucination"**
4. **"Why Your 4-bit Model Dreams of Electric Sheep (And Other Fabricated Facts)"**

## ðŸ”¬ Methodology Notes

### Hallucination Detection
```python
uncertainty_markers = [
    "i don't know", "i'm not sure", "uncertain", "unclear", 
    "cannot determine", "insufficient information", "unable to answer"
]
```

### Response Classification
- **Refusal**: Contains uncertainty markers (GOOD)
- **Correct**: Accurate answer to known questions (GOOD)  
- **Hallucination**: Confident wrong/fabricated answer (BAD)

### Key Metrics
- **Refusal Rate**: % of uncertain questions where model admits ignorance
- **Hallucination Rate**: % of uncertain questions where model fabricates confident answers
- **Sensitivity Score**: How much responses change across hyperparameter settings

## ðŸ’¡ Hypotheses

### Hyperparameter Sensitivity (Testing Now)
- **H1**: Quantized models are less sensitive to temperature changes
- **H2**: Extreme quantization reduces sampling diversity
- **H3**: 4-bit models show flatter response curves across hyperparameters

### Prompt Engineering (Future)
- **H4**: Anti-hallucination prompts work better than quantization for reducing false confidence
- **H5**: Quantized models are less responsive to meta-cognitive prompting
- **H6**: Role-based prompts ("cautious scientist") are more effective than instruction-based

### Expected Counter-Results
- Models may be so overtrained on confidence that no intervention works
- Quantization might preserve prompt-following ability perfectly
- Temperature might not affect uncertainty admission, only creative expression

## ðŸŽª Why This Matters

OpenAI's hypothesis: **Training incentives reward confident guessing over honest uncertainty**

Our experiments test:
1. Does quantization amplify this problem?
2. Does sampling randomness help models admit uncertainty?
3. Can prompt engineering overcome training biases?

**Real-world impact**: Understanding when and how models hallucinate helps deploy them safely in production.